{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ALL_Text_Processing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Listen the ENTIRE Speech (text to audio file) -- using gtts,playsound and pyttsx3\n",
        "\n",
        "2. Text Summarization (shorten the passage) -- using spacy\n",
        "\n",
        "3. #Listen the Summary -- - using gtts,playsound and pyttsx3\n",
        "\n",
        "4. FAQ/QnA on the speech (Questions generation) -- using summarizers\n",
        "\n",
        "5. Word Cloud (Word diagram) -- using wordcloud\n",
        "\n",
        "6. Sentiment Analysis -- using textblob, TFAutoModelForSequenceClassification model and  AutoTokenizer from transformers \n",
        "\n",
        "7_1. POS Tagging (Parts of Speech Tagging) --  using pos_tag from nltk\n",
        "\n",
        "7. NER (Named Entity Recognizer) -- importing displacy from spacy, importing ne_chunk from nltk\n",
        "\n",
        "8. Extract Audio file from the youtube Video : importing Model ('deepspeech-0.9.3-models.pbmm', 'deepspeech-0.9.3-models.scorer') from deepspeech; importig YouTubeVideo, Audio, Image from IPython.display\n",
        "\n",
        "8_1. Speech (youtube video) to Text Transcription using AssemblyAI -- \n",
        "\n",
        "9. Dictionary \n",
        "\n",
        "9_1 Correct the spelling -- synsets from nltk wordnet package\n",
        "\n",
        "10. Get similar sentences from his speech --  Importing PegasusForConditionalGeneration, PegasusTokenizer from transformers.Used ''tuner007/pegasus_paraphrase'' model. \n",
        "\n",
        "11. ANY language to ENGLISH translation -- from transformers import MBartForConditionalGeneration, MBart50TokenizerFast. Used facebook/mbart-large-50-many-to-many-mmt model. "
      ],
      "metadata": {
        "id": "3EC0X90aBiKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Tasks (Stnd. areas)\n",
        "1. Fill-Mask: 2. Question Answering 3. Sentence Similarity 4. Summarization:\n",
        "\n",
        "5. Text Classification 6. Text Generation: 7. Token Classification \n",
        "8. Translation"
      ],
      "metadata": {
        "id": "dGeAJccKoCOw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxzIUqXZlc_J"
      },
      "source": [
        "1. Listen the ENTIRE speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiXqy1HclJT9"
      },
      "source": [
        "!pip install playsound  \n",
        "!pip install pyttsx3  \n",
        "!pip install gTTS\n",
        "import gtts  \n",
        "from playsound import playsound \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjntvZPYlJaU"
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt', 'r') as file:\n",
        "    data = file.read().replace('\\n', '')\n",
        "\n",
        "fhand = data.replace(\"\\ufeff\", \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aL9W1z77vYI"
      },
      "source": [
        "fhand[0:100]\n",
        "t1 = gtts.gTTS(fhand,lang = 'hi')\n",
        "\n",
        "# save the audio file  \n",
        "t1.save(\"welcome.mp3\")\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio('welcome.mp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YAn2LNslSkP"
      },
      "source": [
        "\n",
        "2. Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text."
      ],
      "metadata": {
        "id": "qprVU4vQ5rR7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kWWk4lrlJw1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt', 'r') as file:\n",
        "    data = file.read().replace('\\n', '')\n",
        "\n",
        "fhand = data.replace(\"\\ufeff\", \"\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(fhand)\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwordlist = list(stopwords.words('english'))\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "\n",
        "stopwords = list(STOP_WORDS)\n",
        "stopwords = stopwordlist.extend (['(',')','-',':',',',\"'s\",'!',':',\"'\",\"''\",'--','.',':','?',';''[',']','``','o','’','“','”','”','[',';'])\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(fhand)\n",
        "\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "punctuation = punctuation + '\\n'\n",
        "word_frequencies = {} #making a dictionary\n",
        "for word in doc:\n",
        "  if word.text.lower() not in punctuation:\n",
        "    if word.text not in word_frequencies.keys():\n",
        "      word_frequencies[word.text] =1\n",
        "    else:\n",
        "      word_frequencies[word.text] +=1 #if any word is present more than 1 time\n",
        "\n",
        "max_frequency = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] = word_frequencies[word]/max_frequency\n",
        "\n",
        "  sentence_tokens = [sent for sent in doc.sents]\n",
        "\n",
        "sentence_scores = {} #create dictionary\n",
        "for sent in sentence_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent not in sentence_scores.keys():\n",
        "        sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "\n",
        "        sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "\n",
        "from heapq import nlargest\n",
        "select_length = int(len(sentence_tokens)*.3) #selecting only 10% of the sentences\n",
        "summary = nlargest(select_length,sentence_scores,key = sentence_scores.get)\n",
        "final_summary = [word.text for word in summary]\n",
        "summary = ' '.join(final_summary)\n",
        "\n",
        "# summary\n",
        "\n",
        "fhand = open('summary.txt','w')\n",
        "fhand.write(summary) # Erass all, already writtena and write what has been passed\n",
        "fhand.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UxynPGPCdaDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text summary: 2. Controllable Text Summarization CtrlSum Huggingface\n",
        "\n",
        "!pip install summarizers -q\n",
        "\n",
        "from summarizers import Summarizers\n",
        "summ = Summarizers(type = 'normal', device='cuda') #If you want GPU acceleration, set param device='cuda'. #type = 'paper', type = 'patent'\n"
      ],
      "metadata": {
        "id": "mkTmXSVUdaNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Recent state-of-the-art approaches to summarization utilize large pre-trained Transformer models. Distilling these models to smaller student models has become critically important for practical use; however there are many different distillation methods proposed by the NLP literature. Recent work on distilling BERT for classification and regression tasks shows strong performance using direct knowledge distillation. Alternatively, machine translation practitioners distill using pseudo-labeling, where a small model is trained on the translations of a larger model. A third, simpler approach is to 'shrink and fine-tune' (SFT), which avoids any explicit distillation by copying parameters to a smaller student model and then fine-tuning. We compare these three approaches for distillation of Pegasus and BART, the current and former state of the art, pre-trained summarization models, and find that SFT outperforms knowledge distillation and pseudo-labeling on the CNN/DailyMail dataset, but under-performs pseudo-labeling on the more abstractive XSUM dataset. PyTorch Code and checkpoints of different sizes are available through Hugging Face transformers here this http URL.\"\n",
        "# print(text)\n",
        "print(summ(text, query = 'approaches of distilling'))"
      ],
      "metadata": {
        "id": "ONKEnf8i8eAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = '''\n",
        "\tWhen I was young, the kitchen had an invisible 'stop' sign put there by my mother. “No you cannot enter here!” she always said to me. I don't blame her as it is no place for kids. Fire and sharp stuff are present there.\n",
        "\t\n",
        "\tI alwayswonder the beautiful experience of cooking. This is an art and our mothers are artist, very perfect in making the food delicious. I wanted to cook and my school gave me the project to make a dish of potato and lady finger. This was a golden chance to get in the kitchen and get my apron messy. I called my mother to help as this was my first time cooking and I am not that old to cook by my self. I told my mother about the task and we began.\n",
        "\n",
        "\tShe thought for a while and suggested some dishes. I picked my favourite one. She instructed me and I followed. I was wearing my apron and so was mom. She explained me so sweetly and nicely that I know the recipe by heart. The using of stove and knives were done by her. We were cooking it in the evening for the dinner of the family. \n",
        "\n",
        "\tMy father and my brother also came to help us . We prepared the dish by 8 o'clock and mom gave me to taste some of it. It was delicious and so finely prepared. That day I got to know the work required for making the food that we simply eat it watching television. I ate the food and felt all the spices blend in my mouth. It was a deling for me and my tongue. It was a wonderful experience.\n",
        "\t\t\t\t         \n",
        "                                                                     \" A recipe has no soul. You, as a cook, must bring the soul to the recipe.\"   '''\n",
        "print(summ(text2))\n",
        "\n",
        "print(summ(text2, query = \"What was I cooking ?\" ))\n",
        "#print(summ(text2, query = \"What was I cooking ?\", question_detection=False ))\n",
        "#print(summ(text2, prompt=\"Q:Where is India? A:\"))"
      ],
      "metadata": {
        "id": "TrQWm6Gf8eD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text2 = \"India (Hindi: Bhārat), officially the Republic of India (Hindi: Bhārat Gaṇarājya),[23] is a country in South Asia. It is the second-most populous country, the seventh-largest country by land area, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[f] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar and Indonesia.Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[24] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[25] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[26] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest,[27] unfolding as the language of the Rigveda, and recording the dawning of Hinduism in India.[28][disputed – discuss] The Dravidian languages of India were supplanted in the northern and western regions.[29] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[30] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[31] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[32] Their collective era was suffused with wide-ranging creativity,[33] but also marked by the declining status of women,[34] and the incorporation of untouchability into an organised system of belief.[g][35] In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia.[36]\"\n",
        "\n",
        "print(summ(text2, query = \"What was I cooking ?\", question_detection=False ))"
      ],
      "metadata": {
        "id": "CemsRsAp8eGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summ(text2, prompt=\"Q:Where is India? A:\"))"
      ],
      "metadata": {
        "id": "weuguBkv8eJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summ(text2, query=\"Where is India?\", prompt=\"India is\")) \n",
        "#Generating text is the task of producing new text. These models can, for example, fill in incomplete text or paraphrase (Casual Language Modelling)"
      ],
      "metadata": {
        "id": "an3uvV2U8wFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ(\n",
        "...     contents=text2,\n",
        "...     num_beams=10,\n",
        "...     top_k=30,\n",
        "...     top_p=0.85,\n",
        "...     no_repeat_ngram_size=3,      \n",
        "...     length_penalty=1.2,\n",
        "... )"
      ],
      "metadata": {
        "id": "k7NagDHD8wIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3nO4bUmj8wLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_b6mJRN98eMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujIRli9UsjmY"
      },
      "source": [
        "3. Listen the Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1NHcZMlKAe"
      },
      "source": [
        "# !pip install playsound  \n",
        "# !pip install pyttsx3  \n",
        "# !pip install gTTS\n",
        "# import gtts  \n",
        "# from playsound import playsound \n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %cd \"/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/\"\n",
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/summary.txt', 'r') as file:\n",
        "    data = file.read().replace('\\n', '')\n",
        "\n",
        "fhand = data.replace(\"\\ufeff\", \"\")\n",
        "fhand[0:100]\n",
        "t1 = gtts.gTTS(fhand,lang = 'hi')\n",
        "\n",
        "# save the audio file  \n",
        "t1.save(\"summary.mp3\")\n",
        "\n",
        "from IPython.display import Audio\n",
        "Audio('summary.mp3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwWzihbVuoAa"
      },
      "source": [
        "4. FAQ/QnA on the speech"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!"
      ],
      "metadata": {
        "id": "g8hDxw5UN2uk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMQU1r5SnQJ5"
      },
      "source": [
        "# !pip install summarizers -q\n",
        "\n",
        "# from summarizers import Summarizers\n",
        "# summ = Summarizers(type = 'normal', device='cuda') #If you want GPU acceleration, set param device='cuda'.\n",
        "# # summ = Summarizers(type = 'paper', device='cuda') #If you want GPU acceleration, set param device='cuda'.\n",
        "# # summ = Summarizers(type = 'patent', device='cuda') #If you want GPU acceleration, set param device='cuda'.\n",
        "\n",
        "# text = fhand\n",
        "# text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZeVOc4pnQPy"
      },
      "source": [
        "# print(summ(text, query = \"whom I salute?\", question_detection=False  ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMXDPejF9TIB"
      },
      "source": [
        "# print(summ(text, prompt=\"Q:whom I salute? A:\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXdat1Xb9TLX"
      },
      "source": [
        "# print(summ(text, query=\"Whom I salute?\", prompt=\"I salute countless\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4RmrX2ZnQST"
      },
      "source": [
        "# summ(\n",
        "# ...     contents=text,\n",
        "# ...     num_beams=10,\n",
        "# ...     top_k=30,\n",
        "# ...     top_p=0.85,\n",
        "# ...     no_repeat_ngram_size=3,      \n",
        "# ...     length_penalty=1.2,\n",
        "# ... )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G7B4l8YqjQ92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kT-wvpeRjRAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jmdKkFA4irbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpfLeX_ZDf1d"
      },
      "source": [
        "5. Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "347LsquGnQbT"
      },
      "source": [
        "import pathlib \n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "from PIL import Image \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIgNcmmGDjUB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = pathlib.Path.cwd() /'files'/ '/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt'\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPQVTTMPDjaU"
      },
      "source": [
        "text2 = path.read_text()\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=1000).generate(text2) #,background_color=\"white\"\n",
        "plt.imshow(wordcloud,interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.savefig('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/ML1.png',dpi = 600, facecolor = 'w',format = 'png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uYLh-A6ERGFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVw53rPRlRcm"
      },
      "source": [
        "6. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text classification: Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness."
      ],
      "metadata": {
        "id": "m95LcHbe6O0P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79OseWloDj23"
      },
      "source": [
        "! pip install transformers\n",
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IxZp_CIDj6D"
      },
      "source": [
        "results = classifier('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt')\n",
        "results\n",
        "#[{'label': 'NEGATIVE', 'score': 0.9919876456260681}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47aPjPfdLfHt"
      },
      "source": [
        "#Sentiment Analysis: find the polarity and subjectivity of a sentence\n",
        "# !pip install textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "feedback1 = fhand\n",
        "\n",
        "blob1=TextBlob(feedback1)\n",
        "\n",
        "print(blob1.sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtBtXhJ0l4A_"
      },
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "# This model only exists in PyTorch, so we use the `from_pt` flag to import that model in TensorFlow.\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-SdjNxXl4Dz"
      },
      "source": [
        "results = classifier('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt')\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV1rSw6LS2dd"
      },
      "source": [
        "7_1 POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0XHKCavS1kO"
      },
      "source": [
        "#6 POS Tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "sent= open('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt','r')\n",
        "sent2 = sent.read()\n",
        "sent_tag = nltk.word_tokenize(sent2)\n",
        "\n",
        "for token in sent_tag:\n",
        "  print(nltk.pos_tag([token]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ8O7nbaqQ8a"
      },
      "source": [
        "7. NER (Named Entity Recognizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token Classification: Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks."
      ],
      "metadata": {
        "id": "_eGhRvLp6d0l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Or0tNbxl4R7"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meBva2KqqYJR"
      },
      "source": [
        "doc = nlp(fhand)\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "displacy.render(nlp(doc.text),style='ent', jupyter=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un4SryS4qYS_"
      },
      "source": [
        "#7: NER\n",
        "from nltk import ne_chunk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "ne_sent= open('/content/drive/My Drive/Colab Notebooks/Projects/NLP_ALLTextProcessing/PM’s Speech on 75th Independence Day.txt','r')\n",
        "ne_sent2 = ne_sent.read()\n",
        "\n",
        "ne_token =word_tokenize(ne_sent2)\n",
        "ne_tags = nltk.pos_tag(ne_token)\n",
        "\n",
        "ne_ner = ne_chunk(ne_tags)\n",
        "print(ne_ner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3-QY-tux6V6"
      },
      "source": [
        "8. Extract Audio file from the youtube Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCL9LNHByL1n"
      },
      "source": [
        "!pip install wget \n",
        "!pip install easyocr \n",
        "!pip install deepspeech-gpu==0.9.3 \n",
        "!pip install pafy \n",
        "!pip install youtube-dl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_t6ynbPymIj"
      },
      "source": [
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm \n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKjkbBBfqYWJ"
      },
      "source": [
        "from deepspeech import Model \n",
        "import numpy as np \n",
        "import os \n",
        "import wave \n",
        "# import easyocr \n",
        "import pafy \n",
        "from IPython.display import Audio, Image \n",
        "from IPython.display import YouTubeVideo \n",
        "\n",
        "model_file_path = 'deepspeech-0.9.3-models.pbmm' \n",
        "lm_file_path = 'deepspeech-0.9.3-models.scorer' \n",
        "beam_width = 500  #more beam width, more accuracy but it will take more time also\n",
        "lm_alpha = 0.93 \n",
        "lm_beta = 1.18 \n",
        "model = Model(model_file_path) \n",
        "model.enableExternalScorer(lm_file_path) \n",
        "model.setScorerAlphaBeta(lm_alpha, lm_beta) \n",
        "model.setBeamWidth(beam_width) \n",
        "YOUTUBE_ID = 't23x9gcbamA' \n",
        "YouTubeVideo(YOUTUBE_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvc2iePiqYZR"
      },
      "source": [
        "URL='https://www.youtube.com/watch\\?v\\='+ YOUTUBE_ID \n",
        "!youtube-dl --extract-audio --audio-format wav --output \"YahiSamayhaiSahiSamayHai.%(ext)s\" $URL "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54eWog41qYcj"
      },
      "source": [
        "!ffmpeg -i YahiSamayhaiSahiSamayHai.wav -vn -ar 16000 -ac 1 YahiSamayhaiSahiSamayHai.wav #16000 is the framerate\n",
        "Audio('YahiSamayhaiSahiSamayHai.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0m5yc45qYfr"
      },
      "source": [
        "stream = model.createStream()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZg16Ks8qYil"
      },
      "source": [
        "def read_wav_file(filename):\n",
        "  with wave.open(filename,'rb') as w:\n",
        "    rate = w.getframerate()\n",
        "    frames = w.getnframes()\n",
        "    buffer = w.readframes(frames)\n",
        "  return buffer, rate  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSC7fjc5qYlx"
      },
      "source": [
        "from IPython.display import clear_output \n",
        "def transcribe_streaming(audio_file): \n",
        "  buffer, rate = read_wav_file(audio_file) \n",
        "  offset=0 \n",
        "  batch_size=65536 \n",
        "  text=''\n",
        "\n",
        "  while offset < len(buffer): \n",
        "    end_offset=offset+batch_size \n",
        "    chunk=buffer[offset:end_offset]\n",
        "    datal6 = np.frombuffer(chunk, dtype=np.int16)\n",
        "\n",
        "\n",
        "    stream.feedAudioContent(datal6) \n",
        "    text=stream.intermediateDecode() \n",
        "    #clear output(wait=True) \n",
        "    print(text) \n",
        "    offset=end_offset \n",
        "  return True "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLvZ6VZgqYo3"
      },
      "source": [
        "transcribe_streaming('YahiSamayhaiSahiSamayHai.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdK_mrCXqYsa"
      },
      "source": [
        "def transcribe(audio_file):\n",
        "  buffer, rate =read_wav_file(audio_file)\n",
        "  data16 = np.frombuffer(buffer,dtype = np.int16)\n",
        "  return model.sttWithMetadata(data16)\n",
        "\n",
        "  transcribe('YahiSamayhaiSahiSamayHai.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW1XUCkol4Uq"
      },
      "source": [
        "reader = easyocr.Reader(['en'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O6eBkMy79AZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8_1. Speech (youtube video) to Text Transcription using AssemblyAI"
      ],
      "metadata": {
        "id": "Xm2ZHEWr-Nxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = 'KEY' # get API key from: https://app.assemblyai.com/\n",
        "\n",
        "!pip install pytube\n",
        "\n",
        "# 2. Retrieving audio file from YouTube video\n",
        "from pytube import YouTube\n",
        "video = YouTube(\"https://www.youtube.com/watch?v=mkVjrB8g6mM\")\n",
        "yt = video.streams.get_audio_only()\n",
        "\n",
        "yt.download()\n",
        "\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "for file in os.listdir(current_dir):\n",
        "    if file.endswith(\".mp4\"):\n",
        "        mp4_file = os.path.join(current_dir, file)\n",
        "        print(mp4_file)\n",
        "\n",
        "# 3. Upload YouTube audio file to AssemblyAI\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import requests\n",
        "\n",
        "filename = mp4_file\n",
        "\n",
        "def read_file(filename, chunk_size=5242880):\n",
        "    with open(filename, 'rb') as _file:\n",
        "        while True:\n",
        "            data = _file.read(chunk_size)\n",
        "            if not data:\n",
        "                break\n",
        "            yield data\n",
        " \n",
        "headers = {'authorization': api_key}\n",
        "response = requests.post('https://api.assemblyai.com/v2/upload',\n",
        "                         headers=headers,\n",
        "                         data=read_file(filename))\n",
        "\n",
        "audio_url = response.json()['upload_url']\n",
        "\n",
        "# 4. Transcribe uploaded audio file\n",
        "\n",
        "import requests\n",
        "\n",
        "endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
        "\n",
        "json = {\n",
        "  \"audio_url\": audio_url\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"authorization\": api_key,\n",
        "    \"content-type\": \"application/json\"\n",
        "}\n",
        "\n",
        "transcript_input_response = requests.post(endpoint, json=json, headers=headers)\n",
        "\n",
        "\n",
        "# 5. Extract transcript ID\n",
        "\n",
        "transcript_id = transcript_input_response.json()[\"id\"]\n",
        "\n",
        "\n",
        "\n",
        "# 6. Retrieve transcription results\n",
        "endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcript_id}\"\n",
        "headers = {\n",
        "    \"authorization\": api_key,\n",
        "}\n",
        "\n",
        "transcript_output_response = requests.get(endpoint, headers=headers)\n",
        "\n",
        "print('6. Retrieve transcription results: ',transcript_output_response)\n",
        "\n",
        "transcript_output_response.json()['status']\n",
        "\n",
        "from time import sleep\n",
        "\n",
        "while transcript_output_response.json()['status'] != 'completed':\n",
        "  sleep(5)\n",
        "  print('Transcription is processing ...')\n",
        "  transcript_output_response = requests.get(endpoint, headers=headers)\n",
        "\n",
        "\n",
        "# 7. Print transcribed text\n",
        "print('Output:\\n')\n",
        "print(transcript_output_response.json())\n",
        "\n",
        "# 8. Save transcribed text to file\n",
        "\n",
        "# Save as TXT file\n",
        "yt_txt = open('yt.txt', 'w')\n",
        "yt_txt.write(transcript_output_response.json()[\"text\"])\n",
        "yt_txt.close()\n",
        "\n",
        "\n",
        "# Save as SRT file\n",
        "srt_endpoint = endpoint + \"/srt\"\n",
        "srt_response = requests.get(srt_endpoint, headers=headers)\n",
        "\n",
        "with open(\"yt.srt\", \"w\") as _file:\n",
        "    _file.write(srt_response.text)"
      ],
      "metadata": {
        "id": "5K8oK-vq6kfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ECT2Gzx66kvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5mpctOPGUpo"
      },
      "source": [
        "9. Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfGYXQORFYD8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "#n --> noun\n",
        "# v verb\n",
        "#a or s Adjective\n",
        "#r adverb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnbJ8lMyFYJv"
      },
      "source": [
        "sense_word = input('Enter a word (e.g. cricket): ') #e.g. cricket and then cricket.n.01; day and day.n.04\n",
        "synsets = wn.synsets(sense_word)\n",
        "print('All possible senses for', sense_word,  'is: ',synsets )\n",
        "\n",
        "for sense_word in synsets:\n",
        "    print(\"\\nSense: \", sense_word.name())\n",
        "    print(\"Synonyms: \" , [lemma.name() for lemma in sense_word.lemmas()])\n",
        "    print (\"Anotonyms: \", [lemma.name() for lemma in sense_word.lemmas()[0].antonyms()])\n",
        "    \n",
        "#    print (\"Anotonyms: \", [a.name()for a in wn.synset('day.n.04').lemmas()[0].antonyms()]) \n",
        "    print(\"Gloss Definition: \" + sense_word.definition())\n",
        "    print(\"Example Sentemces: \" + str(sense_word.examples()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84vTBlMCfXfD"
      },
      "source": [
        "9_1 Correct the spelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei6K5PYlFYcD"
      },
      "source": [
        "#10 Usage: Spelling Correction: deletion / insertion / substitution / transposition\n",
        "# !pip install textblob\n",
        "from textblob import TextBlob\n",
        "b = TextBlob(input('Enter word with incorrect spelling: '))\n",
        "print('Correct sentence is:', b.correct())#responsable, sily, arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob, Word\n",
        "for text in ('how arr you doing','another sily mistake','I am responsable'):\n",
        "  print(TextBlob(text).correct())\n",
        "\n",
        "w = Word('sily')\n",
        "w.spellcheck()"
      ],
      "metadata": {
        "id": "yrdBYyMHFFOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tmndxZM-nma"
      },
      "source": [
        "10. Get similar sentences from his speech"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Similarity: Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping."
      ],
      "metadata": {
        "id": "OAnQ5Nti69jE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP-IPtOwgmeY"
      },
      "source": [
        "! pip install sentence-splitter\n",
        "! pip install transformers\n",
        "! pip install SentencePiece\n",
        "\n",
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "model_name = 'tuner007/pegasus_paraphrase'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def get_response(tgt_text,num_return_sequences): #def get_response(input_text,num_return_sequences,num_beams):\n",
        "  batch = tokenizer.prepare_seq2seq_batch(tgt_text,truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
        "\n",
        "  translated = model.generate(**batch,max_length=60,num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text\n",
        "\n",
        "num_return_sequences = 10\n",
        "num_beams = 10\n",
        "\n",
        "tgt_text = \"I have faith in the youth of my country, I trust the sisters of the country, the daughters of the country, the farmers of the country, and the professionals of the country.\"\n",
        "get_response(tgt_text,num_return_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZfau191gmwH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OtZQCmlnhWN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF7uQD3Oroqh"
      },
      "source": [
        "## 11. ANY language to ENGLISH translation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translation: Translation is the task of converting text from one language to another."
      ],
      "metadata": {
        "id": "2Jjf8YTi6xvV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Qry1J5nhgH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/NLP/Language_Translation_mBART-50/\"\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q sentencepiece\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 8501 &')\n",
        "\n",
        "#ORIGINALS \n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ukdu8HrrsSN"
      },
      "source": [
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\") \n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\", src_lang=\"hi_IN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktVf4EhdtHQR"
      },
      "source": [
        "article_en = \"पपीता\"\n",
        "#प्याज,आलू,आलु,\n",
        "model_inputs = tokenizer(article_en, return_tensors=\"pt\")\n",
        "\n",
        "generated_tokens = model.generate(\n",
        "    **model_inputs,\n",
        "    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]#hi_IN\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSE1oQE6rsVt"
      },
      "source": [
        "translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "translation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fdlHQ74rs6w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AAtLMt9HuUd-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}