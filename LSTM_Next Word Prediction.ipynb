{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO8h0chLA/YaJxjN+k938dx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"W-Jujpu42kr0"},"outputs":[],"source":["#PASS\n","#https://www.gutenberg.org/files/236/236-0.txt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.optimizers import RMSprop,Adam"]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM\n","# from keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers import RMSprop\n","import numpy as np\n","import random\n","import sys"],"metadata":{"id":"fIjTaDlA2lR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD TEXT\n","#Save notepad as UTF-8 (select from dropdown during saving)\n","#filename = \"files/the_jungle_book.txt\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","filename = open('/content/drive/My Drive/Colab Notebooks/NLP/NextWordPrediction/the_jungle_book.txt', \"r\", encoding = \"utf8\").read()\n","\n","# lines = []\n","\n","# for i in filename:\n","#     lines.append(i)\n","    \n","\n","# raw_text = open(filename, 'r', encoding='utf-8').read()\n","raw_text = filename\n","raw_text = raw_text.lower()\n","print(raw_text[0:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LrRUVp7BcCa6","executionInfo":{"status":"ok","timestamp":1666273526666,"user_tz":-330,"elapsed":28041,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"c4eb574a-2403-42d5-f96c-49598ce7fe0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","the project gutenberg ebook of the jungle book, by rudyard kipling\n","\n","this ebook is for the use of anyone anywhere at no cost and with\n","almost no restrictions whatsoever.  you may copy it, give it away or\n","re-use it under the terms of the project gutenberg license included\n","with this ebook or online at www.gutenberg.org\n","\n","\n","title: the jungle book\n","\n","author: rudyard kipling\n","\n","release date: january 16, 2006 [ebook #236]\n","last updated: october 6, 2016\n","\n","language: english\n","\n","character set encoding: utf-8\n","\n","*** start of this project gutenberg ebook the jungle book ***\n","\n","\n","\n","\n","produced by an anonymous volunteer and david widger\n","\n","\n","\n","\n","\n","the jungle book\n","\n","by rudyard kipling\n","\n","\n","\n","contents\n","\n","     mowgli’s brothers\n","     hunting-song of the seeonee pack\n","     kaa’s hunting\n","     road-song of the bandar-log\n","     “tiger! tiger!”\n","      mowgli’s song\n","     the white seal\n","     lukannon\n","     “rikki-tikki-tavi”\n","      darzee’s chant\n","     toomai of the elephants\n","     shiv and the grasshopper\n","     her majesty’s servants\n","     parade son\n"]}]},{"cell_type":"code","source":["#CLEAN TEXT\n","#Remove numbers\n","raw_text = ''.join(c for c in raw_text if not c.isdigit())\n"],"metadata":{"id":"VTao5J01cCh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UzazDazHjExX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3cEKK51VjE09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HqqVPTQxjE42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#How many total characters do we have in our training text?\n","chars = sorted(list(set(raw_text))) #List of every character\n","\n","#Character sequences must be encoded as integers. \n","#Each unique character will be assigned an integer value. \n","#Create a dictionary of characters mapped to integer values\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","\n","#Do the reverse so we can print our predictions in characters and not integers\n","int_to_char = dict((i, c) for i, c in enumerate(chars))\n","\n","# summarize the data\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"Total Characters in the text; corpus length: \", n_chars)\n","print(\"Total Vocab: \", n_vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7j2K3ZWGcClA","executionInfo":{"status":"ok","timestamp":1666273526669,"user_tz":-330,"elapsed":19,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"e9941b10-e84b-42de-d71c-6bf91c19aa44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Characters in the text; corpus length:  292869\n","Total Vocab:  50\n"]}]},{"cell_type":"code","source":["# char_to_int"],"metadata":{"id":"RclPpoxCjJE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# int_to_char"],"metadata":{"id":"mGklNVO4jS88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(raw_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etZbPCrijas6","executionInfo":{"status":"ok","timestamp":1666273526671,"user_tz":-330,"elapsed":18,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"57b948d9-3a3f-4a51-ed6a-6cb8476da9d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["292869"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["########################\n","#Now that we have characters we can create input/output sequences for training\n","#Remember that for LSTM input and output can be sequences... hence the term seq2seq\n","\n","\n","seq_length = 60  #Length of each input sequence\n","step = 10   #Instead of moving 1 letter at a time, try skipping a few. \n","sentences = []    # X values (Sentences)\n","next_chars = []   # Y values. The character that follows the sentence defined as X\n","for i in range(0, n_chars - seq_length, step):  #step=1 means each sentence is offset just by a single letter\n","    sentences.append(raw_text[i: i + seq_length])  #Sequence in\n","    next_chars.append(raw_text[i + seq_length])  #Sequence out\n","n_patterns = len(sentences)    \n","print('Number of sequences:', n_patterns)\n","\n","#Have a look at sentences and next_chars to see the continuity..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bShJxmA6cCn3","executionInfo":{"status":"ok","timestamp":1666273526671,"user_tz":-330,"elapsed":16,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"d90a1ee3-405f-496b-a54a-9f2c9a5e0dff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sequences: 29281\n"]}]},{"cell_type":"code","source":["sentences[15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"j15TTVlkklMo","executionInfo":{"status":"ok","timestamp":1666273526672,"user_tz":-330,"elapsed":16,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"8e05b0cc-10ac-4642-c3d1-ec2c68e56830"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'tions whatsoever.  you may copy it, give it away or\\nre-use i'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["next_chars[15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Ja4Iy4XYlQjA","executionInfo":{"status":"ok","timestamp":1666273526672,"user_tz":-330,"elapsed":14,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"94d81a92-73f5-4167-9bc7-26a794bfe377"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'t'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["############################\n","\n","#Just like time series, X is the sequence / sentence and y is the next value\n","#that comes after the sentence... \n","\n","# reshape input to be [samples, time steps, features]\n","\n","#time steps = sequence length\n","#features = numbers of characters in our vocab (n_vocab)\n","#Vectorize all sentences: there are n_patterns sentences.\n","#For each sentence we have n_vocab characters available for seq_length\n","#Vectorization returns a vector for all sentences indicating the presence or absence \n","#of a character. \n","\n","x = np.zeros((len(sentences), seq_length, n_vocab), dtype=np.bool)\n","y = np.zeros((len(sentences), n_vocab), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_to_int[char]] = 1\n","    y[i, char_to_int[next_chars[i]]] = 1\n","    \n","print(x.shape)\n","print(y.shape)\n","\n","print(y[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6yF-vhqcCrO","executionInfo":{"status":"ok","timestamp":1666273527679,"user_tz":-330,"elapsed":1020,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"0af976f4-fe04-4902-e821-9b1e0cc709ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  app.launch_new_instance()\n"]},{"output_type":"stream","name":"stdout","text":["(29281, 60, 50)\n","(29281, 50)\n","[[False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False  True False False False False False False False\n","  False False False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False  True False False False False False False False\n","  False False False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False  True False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False  True False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False  True False\n","  False False False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False  True False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False  True False\n","  False False False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False  True False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False  True False False\n","  False False False False False False False False False False False False\n","  False False]\n"," [False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False False False False False False False False False False\n","  False False False  True False False False False False False False False\n","  False False]]\n"]}]},{"cell_type":"code","source":["##################################################\n","#Basic model with one LSTM\n","# build the model: a single LSTM\n","\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(seq_length, n_vocab)))\n","model.add(Dense(n_vocab, activation='softmax'))\n","\n","optimizer = RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer,run_eagerly=None)\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dRPv06OJc6Wi","executionInfo":{"status":"ok","timestamp":1666273531173,"user_tz":-330,"elapsed":3496,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"2bf06fe7-245c-4dea-d663-1e2010a1233f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 128)               91648     \n","                                                                 \n"," dense (Dense)               (None, 50)                6450      \n","                                                                 \n","=================================================================\n","Total params: 98,098\n","Trainable params: 98,098\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["\n","######################################\n","# Deeper model woth 2 LSTM\n","#To stack LSTM layers, we need to change the configuration of the prior \n","#LSTM layer to output a 3D array as input for the subsequent layer.\n","#We can do this by setting the return_sequences argument on the layer to True \n","#(defaults to False). This will return one output for each input time step and provide a 3D array.\n","#Below is the same example as above with return_sequences=True.\n","\n","#model = Sequential()\n","#model.add(LSTM(128, input_shape=(seq_length, n_vocab), return_sequences=True))\n","#model.add(Dropout(0.2))\n","#model.add(LSTM(128))\n","#model.add(Dropout(0.2))\n","#model.add(Dense(n_vocab, activation='softmax'))\n","\n","#optimizer = RMSprop(lr=0.01)\n","#model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","#model.summary()"],"metadata":{"id":"039ZfRh6c6Zn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["###############\n","\n","\n","# define the checkpoint\n","from keras.callbacks import ModelCheckpoint\n","\n","filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","\n","callbacks_list = [checkpoint]\n"],"metadata":{"id":"R7h1UXwqc6co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fit the model\n","\n","history = model.fit(x, y,\n","          batch_size=128,\n","          epochs=50,   \n","          callbacks=callbacks_list)\n","\n","model.save('my_saved_weights_jungle_book_50epochs.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cr3-Vvwnc6fi","executionInfo":{"status":"ok","timestamp":1666273621511,"user_tz":-330,"elapsed":90345,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"058d7ac4-4151-41e9-890d-018ad19c5d17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","222/229 [============================>.] - ETA: 0s - loss: 2.5187\n","Epoch 1: loss improved from inf to 2.51072, saving model to saved_weights/saved_weights-01-2.5107.hdf5\n","229/229 [==============================] - 8s 8ms/step - loss: 2.5107\n","Epoch 2/50\n","223/229 [============================>.] - ETA: 0s - loss: 2.0535\n","Epoch 2: loss improved from 2.51072 to 2.05112, saving model to saved_weights/saved_weights-02-2.0511.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 2.0511\n","Epoch 3/50\n","224/229 [============================>.] - ETA: 0s - loss: 1.8578\n","Epoch 3: loss improved from 2.05112 to 1.85670, saving model to saved_weights/saved_weights-03-1.8567.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.8567\n","Epoch 4/50\n","229/229 [==============================] - ETA: 0s - loss: 1.7093\n","Epoch 4: loss improved from 1.85670 to 1.70929, saving model to saved_weights/saved_weights-04-1.7093.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.7093\n","Epoch 5/50\n","223/229 [============================>.] - ETA: 0s - loss: 1.5838\n","Epoch 5: loss improved from 1.70929 to 1.58532, saving model to saved_weights/saved_weights-05-1.5853.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.5853\n","Epoch 6/50\n","228/229 [============================>.] - ETA: 0s - loss: 1.4759\n","Epoch 6: loss improved from 1.58532 to 1.47687, saving model to saved_weights/saved_weights-06-1.4769.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.4769\n","Epoch 7/50\n","229/229 [==============================] - ETA: 0s - loss: 1.3827\n","Epoch 7: loss improved from 1.47687 to 1.38268, saving model to saved_weights/saved_weights-07-1.3827.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.3827\n","Epoch 8/50\n","229/229 [==============================] - ETA: 0s - loss: 1.2992\n","Epoch 8: loss improved from 1.38268 to 1.29923, saving model to saved_weights/saved_weights-08-1.2992.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.2992\n","Epoch 9/50\n","223/229 [============================>.] - ETA: 0s - loss: 1.2311\n","Epoch 9: loss improved from 1.29923 to 1.23369, saving model to saved_weights/saved_weights-09-1.2337.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.2337\n","Epoch 10/50\n","229/229 [==============================] - ETA: 0s - loss: 1.1760\n","Epoch 10: loss improved from 1.23369 to 1.17600, saving model to saved_weights/saved_weights-10-1.1760.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.1760\n","Epoch 11/50\n","225/229 [============================>.] - ETA: 0s - loss: 1.1361\n","Epoch 11: loss improved from 1.17600 to 1.13478, saving model to saved_weights/saved_weights-11-1.1348.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.1348\n","Epoch 12/50\n","223/229 [============================>.] - ETA: 0s - loss: 1.0988\n","Epoch 12: loss improved from 1.13478 to 1.10051, saving model to saved_weights/saved_weights-12-1.1005.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.1005\n","Epoch 13/50\n","226/229 [============================>.] - ETA: 0s - loss: 1.0712\n","Epoch 13: loss improved from 1.10051 to 1.07038, saving model to saved_weights/saved_weights-13-1.0704.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.0704\n","Epoch 14/50\n","227/229 [============================>.] - ETA: 0s - loss: 1.0464\n","Epoch 14: loss improved from 1.07038 to 1.04757, saving model to saved_weights/saved_weights-14-1.0476.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.0476\n","Epoch 15/50\n","225/229 [============================>.] - ETA: 0s - loss: 1.0189\n","Epoch 15: loss improved from 1.04757 to 1.01988, saving model to saved_weights/saved_weights-15-1.0199.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.0199\n","Epoch 16/50\n","229/229 [==============================] - ETA: 0s - loss: 1.0045\n","Epoch 16: loss improved from 1.01988 to 1.00453, saving model to saved_weights/saved_weights-16-1.0045.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 1.0045\n","Epoch 17/50\n","225/229 [============================>.] - ETA: 0s - loss: 0.9825\n","Epoch 17: loss improved from 1.00453 to 0.98394, saving model to saved_weights/saved_weights-17-0.9839.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9839\n","Epoch 18/50\n","225/229 [============================>.] - ETA: 0s - loss: 0.9653\n","Epoch 18: loss improved from 0.98394 to 0.96665, saving model to saved_weights/saved_weights-18-0.9667.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9667\n","Epoch 19/50\n","229/229 [==============================] - ETA: 0s - loss: 0.9553\n","Epoch 19: loss improved from 0.96665 to 0.95526, saving model to saved_weights/saved_weights-19-0.9553.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9553\n","Epoch 20/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.9367\n","Epoch 20: loss improved from 0.95526 to 0.93643, saving model to saved_weights/saved_weights-20-0.9364.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9364\n","Epoch 21/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.9325\n","Epoch 21: loss improved from 0.93643 to 0.93305, saving model to saved_weights/saved_weights-21-0.9331.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9331\n","Epoch 22/50\n","225/229 [============================>.] - ETA: 0s - loss: 0.9159\n","Epoch 22: loss improved from 0.93305 to 0.91690, saving model to saved_weights/saved_weights-22-0.9169.hdf5\n","229/229 [==============================] - 2s 10ms/step - loss: 0.9169\n","Epoch 23/50\n","225/229 [============================>.] - ETA: 0s - loss: 0.9026\n","Epoch 23: loss improved from 0.91690 to 0.90459, saving model to saved_weights/saved_weights-23-0.9046.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.9046\n","Epoch 24/50\n","227/229 [============================>.] - ETA: 0s - loss: 0.8787\n","Epoch 24: loss improved from 0.90459 to 0.87933, saving model to saved_weights/saved_weights-24-0.8793.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8793\n","Epoch 25/50\n","224/229 [============================>.] - ETA: 0s - loss: 0.8788\n","Epoch 25: loss did not improve from 0.87933\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8799\n","Epoch 26/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.8698\n","Epoch 26: loss improved from 0.87933 to 0.86969, saving model to saved_weights/saved_weights-26-0.8697.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8697\n","Epoch 27/50\n","222/229 [============================>.] - ETA: 0s - loss: 0.8531\n","Epoch 27: loss improved from 0.86969 to 0.85679, saving model to saved_weights/saved_weights-27-0.8568.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8568\n","Epoch 28/50\n","229/229 [==============================] - ETA: 0s - loss: 0.8399\n","Epoch 28: loss improved from 0.85679 to 0.83986, saving model to saved_weights/saved_weights-28-0.8399.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8399\n","Epoch 29/50\n","227/229 [============================>.] - ETA: 0s - loss: 0.8338\n","Epoch 29: loss improved from 0.83986 to 0.83540, saving model to saved_weights/saved_weights-29-0.8354.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8354\n","Epoch 30/50\n","229/229 [==============================] - ETA: 0s - loss: 0.8233\n","Epoch 30: loss improved from 0.83540 to 0.82332, saving model to saved_weights/saved_weights-30-0.8233.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8233\n","Epoch 31/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.8190\n","Epoch 31: loss improved from 0.82332 to 0.81905, saving model to saved_weights/saved_weights-31-0.8191.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8191\n","Epoch 32/50\n","226/229 [============================>.] - ETA: 0s - loss: 0.8001\n","Epoch 32: loss improved from 0.81905 to 0.80092, saving model to saved_weights/saved_weights-32-0.8009.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.8009\n","Epoch 33/50\n","226/229 [============================>.] - ETA: 0s - loss: 0.7966\n","Epoch 33: loss improved from 0.80092 to 0.79838, saving model to saved_weights/saved_weights-33-0.7984.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7984\n","Epoch 34/50\n","223/229 [============================>.] - ETA: 0s - loss: 0.7812\n","Epoch 34: loss improved from 0.79838 to 0.78570, saving model to saved_weights/saved_weights-34-0.7857.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7857\n","Epoch 35/50\n","227/229 [============================>.] - ETA: 0s - loss: 0.7738\n","Epoch 35: loss improved from 0.78570 to 0.77453, saving model to saved_weights/saved_weights-35-0.7745.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7745\n","Epoch 36/50\n","229/229 [==============================] - ETA: 0s - loss: 0.7733\n","Epoch 36: loss improved from 0.77453 to 0.77335, saving model to saved_weights/saved_weights-36-0.7733.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7733\n","Epoch 37/50\n","229/229 [==============================] - ETA: 0s - loss: 0.7463\n","Epoch 37: loss improved from 0.77335 to 0.74630, saving model to saved_weights/saved_weights-37-0.7463.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7463\n","Epoch 38/50\n","224/229 [============================>.] - ETA: 0s - loss: 0.7443\n","Epoch 38: loss improved from 0.74630 to 0.74413, saving model to saved_weights/saved_weights-38-0.7441.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7441\n","Epoch 39/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.7327\n","Epoch 39: loss improved from 0.74413 to 0.73217, saving model to saved_weights/saved_weights-39-0.7322.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7322\n","Epoch 40/50\n","222/229 [============================>.] - ETA: 0s - loss: 0.7326\n","Epoch 40: loss did not improve from 0.73217\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7344\n","Epoch 41/50\n","229/229 [==============================] - ETA: 0s - loss: 0.7250\n","Epoch 41: loss improved from 0.73217 to 0.72496, saving model to saved_weights/saved_weights-41-0.7250.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7250\n","Epoch 42/50\n","224/229 [============================>.] - ETA: 0s - loss: 0.7144\n","Epoch 42: loss improved from 0.72496 to 0.71620, saving model to saved_weights/saved_weights-42-0.7162.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7162\n","Epoch 43/50\n","229/229 [==============================] - ETA: 0s - loss: 0.7054\n","Epoch 43: loss improved from 0.71620 to 0.70544, saving model to saved_weights/saved_weights-43-0.7054.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7054\n","Epoch 44/50\n","229/229 [==============================] - ETA: 0s - loss: 0.7053\n","Epoch 44: loss improved from 0.70544 to 0.70532, saving model to saved_weights/saved_weights-44-0.7053.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.7053\n","Epoch 45/50\n","223/229 [============================>.] - ETA: 0s - loss: 0.6925\n","Epoch 45: loss improved from 0.70532 to 0.69351, saving model to saved_weights/saved_weights-45-0.6935.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6935\n","Epoch 46/50\n","229/229 [==============================] - ETA: 0s - loss: 0.6846\n","Epoch 46: loss improved from 0.69351 to 0.68461, saving model to saved_weights/saved_weights-46-0.6846.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6846\n","Epoch 47/50\n","226/229 [============================>.] - ETA: 0s - loss: 0.6796\n","Epoch 47: loss improved from 0.68461 to 0.68016, saving model to saved_weights/saved_weights-47-0.6802.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6802\n","Epoch 48/50\n","228/229 [============================>.] - ETA: 0s - loss: 0.6700\n","Epoch 48: loss improved from 0.68016 to 0.67018, saving model to saved_weights/saved_weights-48-0.6702.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6702\n","Epoch 49/50\n","227/229 [============================>.] - ETA: 0s - loss: 0.6560\n","Epoch 49: loss improved from 0.67018 to 0.65668, saving model to saved_weights/saved_weights-49-0.6567.hdf5\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6567\n","Epoch 50/50\n","224/229 [============================>.] - ETA: 0s - loss: 0.6583\n","Epoch 50: loss did not improve from 0.65668\n","229/229 [==============================] - 2s 7ms/step - loss: 0.6604\n"]}]},{"cell_type":"code","source":["##########################################################################\n","\n","from matplotlib import pyplot as plt\n","#plot the training and validation accuracy and loss at each epoch\n","loss = history.history['loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'y', label='Training loss')\n","plt.title('Training loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"QnAyb26uc6is","executionInfo":{"status":"ok","timestamp":1666273621513,"user_tz":-330,"elapsed":48,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"4470bd68-14ba-4e68-f683-0a08bd67cbd3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["####################################################################\n","###################################\n","#Generate characters \n","#We must provide a sequence of seq_lenth as input to start the generation process\n","\n","#The prediction results is probabilities for each of the 48 characters at a specific\n","#point in sequence. Let us pick the one with max probability and print it out.\n","#Writing our own softmax function....\n","def sample(preds):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds)\n","    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1) \n","    return np.argmax(probas)\n"],"metadata":{"id":"xc4ZCP7cc6ln"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prediction\n","# load the network weights\n","filename = \"my_saved_weights_jungle_book_50epochs.h5\"\n","model.load_weights(filename)\n"],"metadata":{"id":"NlnNkc2xc6or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Pick a random sentence from the text as seed.\n","start_index = random.randint(0, n_chars - seq_length - 1)"],"metadata":{"id":"JmziBCx8c6ry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(start_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcJ320q6iN-7","executionInfo":{"status":"ok","timestamp":1666273621516,"user_tz":-330,"elapsed":47,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"02d30cc5-cd33-423f-c962-84dcd2ab3661"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["int"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["#Initiate generated text and keep adding new predictions and print them out\n","generated = ''\n","sentence = raw_text[start_index: start_index + seq_length]\n","generated += sentence\n"],"metadata":{"id":"gZ6eSGzUc6uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('----- Seed for our text prediction: \"' + sentence + '\"')\n","#sys.stdout.write(generated)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzDe4gqyc6xv","executionInfo":{"status":"ok","timestamp":1666273621523,"user_tz":-330,"elapsed":45,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"05b59c35-35c3-4e14-d91d-1551f57e4bb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----- Seed for our text prediction: \"wn bear who teaches the wolf cubs the law of the jungle:\n","old\"\n"]}]},{"cell_type":"code","source":["for i in range(400):   # Number of characters including spaces\n","    x_pred = np.zeros((1, seq_length, n_vocab))\n","    for t, char in enumerate(sentence):\n","        x_pred[0, t, char_to_int[char]] = 1.\n","\n","    preds = model.predict(x_pred, verbose=0)[0]\n","    next_index = sample(preds)\n","    next_char = int_to_char[next_index]\n","\n","    generated += next_char\n","    sentence = sentence[1:] + next_char\n","\n","    sys.stdout.write(next_char)\n","    sys.stdout.flush()\n","print()\n","\n","############################################"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjsK6BDJ2lVY","executionInfo":{"status":"ok","timestamp":1666273640622,"user_tz":-330,"elapsed":19140,"user":{"displayName":"Vikas Kumar","userId":"15647922538381583982"}},"outputId":"8ce76abc-420b-4021-bbce-ab9a46711c01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" kill koo-thant the stoon year. egraran elephant\n","this is i will\n","lef.” re had not\n","min of the ndrays place fast.\n","\n","          their not clais, fathereng i!  a mong to killi-tuking his head clear on the stood stillnt where huntor scakeg his serven. for the\n","council knack was a mine--- ever mend of the never thee, seal where, but hea! mowgli bouboes obe groves. and the bandar’s came and each is skil-ton \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9e2wyAQ22lYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bwmlCABv2lbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0PSd7Hrs2le_"},"execution_count":null,"outputs":[]}]}